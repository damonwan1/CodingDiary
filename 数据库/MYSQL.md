---
title：Mysql笔记
category:faq
---
<!-- TOC -->

- .1. 基础架构
    - .1.1. 连接器
    - .1.2. 查询缓存
    - .1.3. 分析器
    - .1.4. 优化器
    - .1.5. 执行器
    - .1.6. 存储引擎
- .2. 日志系统
    - .2.1. 重做日志 redo log （InnoDB引擎的日志）
    - .2.2. 归档日志 binlog （Server层的日志）
- .3. 事务
    - .3.1. 名词
    - .3.2. 启动方式
    - .3.3. 视图（Mysql中有两个视图概念）
    - .3.4. 隔离性
    - .3.5. 事务原理（RR/RC）
- .4. 索引
    - .4.1. 索引组织表
    - .4.2. 索引中的名词
    - .4.3. 哈希索引
    - .4.4. 有序数组索引
    - .4.5. B+树索引
        - .4.5.1. InnoDB实现的B+树索引
    - .4.6. 场景
    - .4.7. 索引相关资料
- .5. 锁
    - .5.1. 全局锁
    - .5.2. 表级锁
    - .5.3. 行锁
- .6. 存储
    - .6.1. change buffer（普通索引可用）
- .7. MYSQL调优
- .8. 实战问题
    - .8.1. 如何避免长事务？
    - .8.2. 内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住
- .9. 其他知识点
    - .9.1. 局部性原理

<!-- /TOC -->

### .1. 基础架构
* 一条sql在mysql中执行的流转过程：
![mysql流转过程图](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)
Mysql是插件式的，存储引擎层负责数据的存储和提取，支持InnoDB、MyISAM、Memory等，从图中可以看出，不同的存储引擎共用一个 Server 层，也就是从连接器到执行器的部分；
* 客户端到server层中间可以使用数据库连接池，减少频繁开关连接的资源消耗；

#### .1.1. 连接器
* 负责跟客户端建立连接、获取权限、维持和管理连接
``` SQL
mysql -h$ip -P$port -u$user -p
输入密码
```
* 注意：一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，**只有再新建的连接**才会使用新的权限设置；
* show processlist 命令可以查看连接状态，有sleep（空闲状态）、query等；默认空闲8个小时就会断开，由wait_timeout参数设置；
* 由于建立连接过程复杂，建议使用**长连接**，但是长连接也有坑：
    * MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的**内存是管理在连接对象**里面的。这些资源会在**连接断开的时候才释放**。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了；
    * 解决方案1：定期断开长连接 或 占大内存的查询后，断开连接；
    * 解决方案2：MYSQL5.7后，通过mysql_reset_connection来重新初始化连接资源。

#### .1.2. 查询缓存
* 之前执行过的语句及其结果可能会以key-value的形式存在查询缓存中；
* 查询缓存不推荐使用（mysql8.0后已被删除查询缓存）：
    * 失效频繁：只要有对一个表任何一行的更新，这个表所有查询缓存都被清空。因此只使用于静态表的业务，如系统配置表；
```
显示指定使用查询缓存
mysql> select SQL_CACHE * from T where ID=10；
```

#### .1.3. 分析器
* 词法分析：MySQL 需要识别出里面的字符串分别是什么，代表什么；
    * MySQL 从你输入的"select"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”；
* 语法分析： 判断你输入的这个 SQL 语句是否满足 MySQL 语法；
* 解析器处理语法和解析查询, 生成一课对应的**解析树**。预处理器进一步检查解析树的合法。比如: 数据表和数据列是否存在, 别名是否有歧义等。如果通过则生成新的解析树，再提交给优化器。

#### .1.4. 优化器
* 优化器是在表里面有多个索引的时候，**决定使用哪个索引**；或者在一个语句有多表关联（join）的时候，决定各个**表的连接顺序**

#### .1.5. 执行器
* 开始执行语句。
    * 开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误；
    * 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个**引擎提供的接口**
* 数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行，在有些场景下，执行器调用一次，在引擎内部则扫描了多行，**因此引擎扫描行数跟 rows_examined 并不是完全相同的**；

#### .1.6. 存储引擎
* MyISAM、InnoDB、Memory
* 存储引擎分为多种，不同的存放位置，不同的文件格式
    * InnoDB：磁盘；
        * 聚簇索引：数据和文件存放再一起；
        * .frm:存放表结构
        * .ibd：存放数据文件和索引文件
        * 默认情况下会把所有的数据文件放到表空间中，不会为每一个单独的表保存一份数据文件；如果需要每一个表单独使用文件保存，设置set global innodb_file_per_table=on;
    * MyISAM：磁盘
        * 非聚簇索引：数据和索引单独一个文件
        * .frm:存放表结构
        * .MYI:存放索引数据
        * .MYD:存放实际数据
    * Memory：内存

### .2. 日志系统

#### .2.1. 重做日志 redo log （InnoDB引擎的日志）
* 类比记忆：孔乙己的酒馆，先黑板记账，后台还有一个账本，这叫WAL(Weite-Ahead Logging)；redo log就相当于黑板
* redo log包括两部分：一是内存中的**日志缓冲(redo log buffer)**，该部分日志是易失性的；二是磁盘上的**重做日志文件(redo log file)**，该部分日志是持久的。
* 原因：如果每一次的**更新操作**都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高；使用Redolog是顺序写，并且可以组提交，还有别的一些优化，收益最大是是这两个因素；
* 记录类型：Redo log不是记录数据页“更新之后的状态”，而是记录这个页**做了什么改动**
    * 记录普通数据页的改动；
    * 记录change buffer的改动
![redo log](https://static001.geekbang.org/resource/image/16/a7/16a7950217b3f0f4ed02db5db59562a7.png)
* write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。
* write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。
* 思想：有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 **crash-safe**

#### .2.2. 归档日志 binlog （Server层的日志）
* 记录类型：Binlog有两种模式，statement格式的话是记sql语句， row格式（推荐）会记录行的内容，记两条，更新前和更新后都有。
* binlog和redolog 区别？
    * redo log 是**物理日志**，记录的是“在某个数据页上做了什么修改”；binlog 是**逻辑日志**，记录的是**这个语句的原始逻辑**，比如“给 ID=2 这一行的 c 字段加 1 ”
    * redo log 是**循环写的**，空间固定会用完；binlog 是可以**追加写入**的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
* 为了保证binlog 和 redo log的一致性，redo log 有prepare/commit状态，也称**两阶段提交**：
![两阶段提交](https://static001.geekbang.org/resource/image/2e/be/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png)
上图浅色是咋InnoDB中执行的，深色是在执行器中执行的；
* 这时候redolog只是完成了prepare, 而binlog又失败，那么事务本身会回滚。
---
* 怎么让数据库回复到半个月内任意一秒的状态？
    * 数据库需要定期做整库备份
    * 找到最近的一次全量备份，从备份的时间点起，将之后的binlog一次取出来，重放到你想要的时刻；
* 参数设置（保证事务成功，日志落盘）：
    * sync_binlog = 1，表示每次事务的 binlog 都持久化到磁盘（建议设置）
    * innodb_flush_log_at_trx_commit = 1，表示每次事务的 redo log 都直接持久化到磁盘（建议设置）

### .3. 事务
* 事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的；
* InnoDB支持事务，MyISAM不支持事务；
* 事务的ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）

#### .3.1. 名词
* 一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性；
* 当前读，总是读取已经提交完成的最新版本；

#### .3.2. 启动方式
* 显示启动，begin或start transaction / start transaction with consistent snapshot；提交：commit；回滚：rollback；
    * begin或start transaction，一致性视图是在执行**第一个快照__读__语句**时创建的；
    * tart transaction with consistent snapshot, 一致性视图是在执行 start transaction with consistent snapshot 时创建的。
* set autocommit = 1，自动提交事务； = 0，不会自动提交，哪怕只执行一个select这个事务将一直存在，直到下一次的commit（导致长事务）；
* 建议使用 set autocommit = 1；
* 频繁使用的场景下，减少一次交互，可以使用 commit work and chain（提交事务并自动启动下一个事务，不用再begin了）
* 查询长事务：information_schema 库的 innodb_trx 这个表中查询长事务
``` SQL
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```

#### .3.3. 视图（Mysql中有两个视图概念）
* 一个是 view。它是一个**用查询语句定义的虚拟表**，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。
* 另一个是 InnoDB 在实现 MVCC 时用到的**一致性读视图**，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。

#### .3.4. 隔离性
* 多个事务同时执行会出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，解决这些问题就出现**隔离级别**的概念。
* 事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable)
    * 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
    * 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
    * 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。在当前事务提交之前，其它不论什么事务均不能够**改动或删除**当前事务已读取的数据，可是并没有强制不能**插入**新的满足条件查询的数据行；
    * 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行
* 实现方式：数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准
    * 在“读提交”隔离级别下，这个视图是在每个 SQL **语句开始执行**的时候创建的。
    * “**读未提交**”隔离级别下**直接返回记录上的最新值**，没有视图概念；
    * 在“可重复读”隔离级别下，这个视图是在**事务启动时创建的**，整个事务存在期间都用这个视图。
    * “**串行化**”隔离级别下直接用**加锁**的方式来避免并行访问。
* InnoDB默认隔离级别是RR，可重复度；参数transaction-isolation设置隔离级别；
---
* 可重复读 的实现方式 - 多版本并发控制（MVCC）
    * MVCC实现的读写不阻塞正如其名：多版本并发控制--->通过一定机制生成一个数据请求**时间点的一致性数据快照**（Snapshot)，并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度来看，好像是**数据库可以提供同一数据的多个版本**
* 在 MySQL 中，实际上每条记录在**更新的时候**都会同时**记录一条回滚操作**。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。
* 假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录：
![回滚日志](https://static001.geekbang.org/resource/image/d9/ee/d9c313809e5ac148fc39feff532f0fee.png)
* 在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。
* 回滚日志总不能一直保留吧，什么时候删除呢？当系统里没有比这个回滚日志更早的 read-view 的时候。
* 因此长事务的回滚日志会占用大量存储空间；

#### .3.5. 事务原理（RR/RC）
* 数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id：
    * InnoDB里每个事务开始时候都向事务系统申请一个**唯一**的事务ID（transaction ID），是按照**申请顺序严格递增的**
    * 每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。
![](https://static001.geekbang.org/resource/image/68/ed/68d08d277a6f7926a41cc5541d3dfced.png)
* 图上的三个虚线箭头，就是 undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 依次执行 U3、U2 算出来。
* 因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本（一个一个找，直到找到一个可见的）”
    * 实现：每个事务创建一个**数组**，保存事务启动瞬间，正在“活跃”（启动了但未提交）的所有事务ID；
    * 低水位：**数组**里面的**最小事务ID**；
    * 高水位：当前**系统中**已经创建过的最大事务ID + 1；
    * 数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。
![](https://static001.geekbang.org/resource/image/88/5e/882114aaf55861832b4270d44507695e.png)
（感觉图三的黄色块上的文字有一点点误导，其实黄色块只是大于低水位小于高水位，但是黄色块中也有已提交的事务，并不是全都是未提交事务，而黄色块里的事务提交没提交，正是要通过活跃事务数组判断的。黄色块中的事务，且在活跃事务数组中的部分，是生成快照时还未提交的事务；黄色块中的事务，且不在活跃事务数组中的部分，是生成快照时已经提交了的事务。
总的来说，事务ID高于高水位（当前系统里已经创建过的事务ID的最大值）的一定是建立快照时还没创建的，那么对当前事务不可见；小于高水位的且在活跃事务数组中的，说明建立快照时它还在活跃，一定是还没提交的，那么对当前事务不可见；小于高水位且不在活跃事务数组中的，说明建立了快照时它已经提交了，那么对当前事务可见。）
* 对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：
* 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
* 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；
* 如果落在黄色部分，那就包括两种情况
    * a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；
    * b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。
* 优点：InnoDB 利用了“**所有数据都有多个版本**”的这个特性，实现了“秒级创建快照”的能力。
* 总结：（针对于查询）一个数据版本，对于一个事务视图来说，除了**自己的更新总是可见**以外，有三种情况：
    * 版本未提交，不可见；
    * 版本已提交，但是是在视图创建后提交的，不可见；
    * 版本已提交，而且是在视图创建前提交的，可见。
* **更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）**。其实，除了 update 语句外，select 语句**如果加锁**，也是当前读。
---
* 总结：
* 可重复读的核心就是**一致性读**（consistent read）；而事务**更新数据**的时候，只能用**当前读**。如果当前的记录的**行锁被其他事务占用**的话，就需要进入**锁等待**；

### .4. 索引
* 索引的出现就是为了提高数据库的查询效率，就像书的目录一样；

#### .4.1. 索引组织表
* 在 InnoDB 中，表都是根据主键顺序以索引的形式存放的（以聚簇索引构建的表叫聚簇索引表,又称索引组织表），这种存储方式的表称为索引组织表。

#### .4.2. 索引中的名词
* 聚簇索引 （clustered index），也叫主键索引，primary key，不允许空值，其叶子结点存的是**整行的数据**；
* 二级索引（secondary index），也叫辅助索引、非主键索引、普通索引，其叶子结点内容是**主键的值**，列不是主键列也不是唯一列，在此上的索引；
* 唯一索引：非主键且键是唯一的，允许空置，主键索引不允许空值；
* 全文索引：
* 组合索引：一个索引包含多个列，多个列共同组成索引
* 回表：使用二级索引，查询到的内容叶子结点不包含，需要**回表用主键索引**再查一遍；
* 覆盖索引：不需要回表，索引查询的叶子结点存储的内容已经覆盖了我们的查询需求；
    * explain sql中 extra:using index 含义 -> 使用了覆盖索引
* 最左前缀原则（针对组合索引）：
  * 有一个name age 的组合索引
    * 必须要先匹配name 才能匹配到age
    * **where age = ? and name = ? 也是会匹配，优化器会调整顺序**
    * **where age = ? 不会匹配**
    * or 可能不走索引
    * 因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。
    * 如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引；这时候考虑空间，哪个字段空间小用哪个；
* 索引下推优化（组合索引）：可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数；**把server层的筛选放到了引擎做**
    * 有一个name age 的组合索引
    * （mysql5.6以前）先根据name去存储引擎中拿到所有的数据，然后在server层对age进行数据过滤
    * （mysql5.6以后）根据name，age两个列的值去获取数据，直接把数据返回；
* 页分裂：索引维护过程中，**插入**一个数据，但是数据页已满，需要申请一个新的数据页并挪动；
* 页合并：索引维护过程中，相邻的两个页**删除**了数据，利用率很低，就会合并；
* 主键自增：1、increment推荐使用，防止插入主键数据**触发页分裂**，自增的主键就可以了；2、内存上考虑，整形的自增主键比长字符串**占用空间更小**，而且普通索引的叶子结点空间也更小（因为他们存了主键的值）；

#### .4.3. 哈希索引
* 底层用哈希表实现，每次在添加索引的时候需要计算指定列的hash值，取模运算后计算出下标，将元素插入下标位置即可；
* 只适用于**等值查询**的场景
* 需要将全部数据加载到内存，比较耗空间
* Mysql的MEMORY引擎、Memcached等Nosql引擎

#### .4.4. 有序数组索引
* 底层用数组实现
* 适用于**等值查询和范围查询**，查询使用二分法O(logN)
* 插入效率低，需要挪动后序数组，因此只是用于**静态存储引擎**

#### .4.5. B+树索引
* B+树实现
* 折中考虑了查询和插入，因此都很高效；

##### .4.5.1. InnoDB实现的B+树索引
* 每个表中的每个索引都对应一棵B+树；
* 选用底层数据结构的历程：
    * 二叉树 -> BST -> AVL -> RED/Black（近似平衡树，插入和查找折中）/ B树 -> B+树
        * AVL是严格的平衡树，高度差不能超过1，因此每次元素插入都得进行**1-N次的旋转**，严重影响性能
        * 红黑树是AVL树的升级，损失了部分查询性能，来**提升插入性能**的提升。最低子树和最高子树高度差**2倍以下**即可，不需要进行N次旋转，加入变色特性，满足插入和查询性能的提升。
        * 但是这些二叉树都不适合，因为树的**深度**无法控制造成**IO次数变多**、而且插入性能不佳；
    * B树有个概念叫做Degree，度，可以插入一个数据页的数据；
        * 每次将一个结点读入内存，进行比较
        * 每个结点都有指针、key和data，而每个页的存储是有限的，如果data较大的话，导致每个结点存储的key的总数变小，那么树的深度肯定会增大；
        * 深度增大了，IO次数就增多了，性能下降了；
    * B+树，为了扩大存储的条数，非叶子节点只存key和指针，叶子节点存数据；叶子节点相互用双向链表连接，支持顺序读取。B+树本身支持随机读取，那么顺序和随机都支持了；
        * B+树相比与B树，每个结点可以包含更多的key（因为非叶子结点存储**key和指针**，叶子结点才保存key和**数据**）
        * 那么在同样页大小的空间下，一个非叶子结点存储的key将大大提高，因此深度会极具下降；
        * 叶子结点使用双向链表，支持顺序查询；
    * InnoDB是通过B+树对主键创建索引，然后叶子节点中存储完整记录。选取得顺序为，如果没有主键，那么选唯一键，如果没有唯一键，那么会生成一个6字节得row_id来作为主键；
        * 主键->唯一键->6字节的rowid；
    
* 为什么选B+，为什么不用红黑树/有序数组呢？
    * IO性能，二叉树高度影响了IO次数； 
    * 按页存储，不是按值，契合B+树的度；
    * 文件系统和数据库的索引都是存在硬盘上的，并且如果数据量大的话，不一定能一次性加载到内存中，如果使用数组，那么需要把整个数组都加载进内存，B+树可以加载一个结点一个结点的找；

#### .4.6. 场景
* 该表只有一个索引且是唯一索引（即KV场景），就可以不用自增主键，”尽量使用主键查询”原则，直接将这个业务字段设置为主键，可以避免每次查询需要搜索两棵树。

#### .4.7. 索引相关资料
* [漫画图解MysqlB+\红黑树\数组区别](https://blog.csdn.net/qq_29373285/article/details/88610654)

### .5. 锁
* 按照加锁的范围，MYSQL里面的锁分为：**全局锁、表级锁和行锁**；
* 业务的更新，增删改数据（DML)，加字段等修改表结构的操作（DDL）；

#### .5.1. 全局锁
* 全局锁就是对整个**数据库实例**加锁：全局读锁（Flush tables with read lock - FTWRL）；
* 描述：当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。
* 场景：全库逻辑备份（在备份过程中整个库完全处于只读状态）
    * 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
    * 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。
* 替代： 因为实际上就是要保证备份时候，视图是逻辑一致不变的；
    * 使用官方逻辑备份工具mysqldump，并且使用参数-single-transaction，保证启动一个事务，这样RR隔离性下，拿到一致性视图，可以代替全局锁；
    * 全库只读，设置set global readonly = true；
* 选择： **像使用MyISAM引擎的，只能使用FTWRL，因为不支持事务；其他情况选择single-transaction，不建议使用全库设置readonly**（在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库、如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。）；

#### .5.2. 表级锁
* 表级锁有两种表级别的锁：**表锁 、 元数据锁（meta data lock， MDL）**
* 表锁：** lock tables...read/write  -> unlock tables（或者客户端断开连接自动释放）
* 示例： 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表；
* 场景：对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发；
---
* 元数据锁（MDL）：**MDL 不需要显式使用，在访问一个表的时候会被自动加上**。MDL 的作用是，保证读写的正确性；
* 事务中的 MDL 锁，在**语句执行开始时申请**，但是语句结束后并不会马上释放，而会等到**整个事务提交后再释放**；
* 场景：（mysql5.5后系统自动加）当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。
    * **读锁之间不互斥**，因此你可以有多个线程同时对一张表增删改查。
    * **读写锁之间、写锁之间是互斥的**，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。
---
* 线上坑：虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。**给一个小表加个字段，导致整个库挂了**
    * A、B、C、D四个session，A、B对表t进行增删改查，分别获得读锁没问题；C对表t进行字段修改是写锁，而A、B还未释放读锁（A、B长事务，占用时间长），因此C被阻塞。问题是，之后的D、E、F、G也只是增删改查的读锁，但是由于C被阻塞，mysql内部有个等待队列，他们也被阻塞，对外表现为这个表完全不可读写了；
    * 这时候，如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满；
* 解决线上坑：**如何安全给小表加字段？**
    * 解决长事务：当有DDL变更的表，先暂停DDL或者kill长事务；
    * alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃，之后再循环这个过程（热点表请求频繁的情况下），语法如下：
    ``` SQL
   ALTER TABLE tbl_name NOWAIT add column ...
   ALTER TABLE tbl_name WAIT N add column ... 
    ```
* mysql 5.6支持online ddl，也就是对表操作增加字段等功能；
* Online DDL的过程是这样的：
1. 拿MDL写锁
2. 降级成MDL读锁
3. 真正做DDL
4. 升级成MDL写锁
5. 释放MDL锁

1、2、4、5如果没有锁冲突，执行时间非常短。第3步占用了DDL绝大部分时间，这期间这个表可以正常读写数据，是因此称为“online ”，但是刚刚的例子，是在第一步就堵住了；

#### .5.3. 行锁
* 概念：行锁就是针对数据表中行记录的锁，但不一定是锁行（也可以锁索引），看各个引擎实现；
* MYSQL的行锁是在引擎层由各个引擎自己实现的，但并不是所有的引擎都支持行锁。
* 实现：InnoDB行锁是通过给索引上的索引项加锁来实现的。如果update的列没建索引，即使只update一条记录也会锁定整张表吗？是的，无索引情况，在两个不同事务中，更新同一列加不加limit 1，效果都是锁互斥；原因是没有索引的话，会导致全表扫描(表锁)，同时还会涉及回表(行锁)；
* 牢记：InnoDB这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！**
* 注意：**由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的**
---
* **两阶段锁协议**：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放（commit才释放，而不是语句结束）；
* 场景：如果事务中需要锁多个行，那么尽量把**最可能造成锁冲突的行往后放**；
---
* 线上坑：电影票影院特价预售购买活动，Mysql挂了，上线查看，CPU消耗近100%，但整个数据库每秒就执行不到100个事务，why？
    * 很可能打开了**死锁检测**，导致O(n)级别的遍历，每个加入的线程都需要判断自己加入是否会导致死锁，如果并发量很大，这个CPU就会消耗很大，但是每秒却执行不了几个事务；
    * 解决方案1：业务代码确保不出现死锁，然后临时关掉死锁检测；
    * 解决方案2：使用中间件设置队列控制并发度，同时只允许10个线程更新，那么死锁检测的成本就会降低。
    * 解决方案3： 改变设计策略，因为实际上是 **增加影院账户余额的这行表被锁导致冲突**，那么把这行拆分成10行，以后统计影院账户余额把10行余额加起来不就可以了？现在冲突概率降低成了之前的1/10；
    ---
上面的延申，什么是**死锁**？
* **死锁**：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁；
    * 解决方案1：设置等待时间，直到超时。innodb_lock_wait_timeout;默认是50s，这个等待时间在线上系统是不能接受的，出现死锁等50s太夸张了吧，但是设太小了，可能没有死锁，只是在阻塞等待另一个事务执行而已。
    * 解决方案2：**主动死锁检测**，innodb_deadlock_detect默认就是打开的on，但是这个是由额外的开销的。检测自己锁住的和别的线程锁住的，是否存在相互依赖等待。
* 关于死锁检测
1. 一致性读不会加锁，就不需要做死锁检测；
（一致性读，又称为快照读。使用的是MVCC机制读取undo中的已经提交的数据。所以它的读取是非阻塞的。）
2. 并不是每次死锁检测都都要扫所有事务（算法中环的检测）。比如某个时刻，事务等待状态是这样的：

   B在等A，
   D在等C，
   现在来了一个E，发现E需要等D，那么E就判断跟D、C是否会形成死锁，这个死锁检测不用管B和A；
---
锁附录：
* [各种锁的介绍](https://www.csdn.net/gather_20/MtTaMgzsNDkxNy1ibG9n.html)


### .6. 存储

#### .6.1. change buffer（普通索引可用）
* 在唯一索引和普通索引都可得情况下，建议使用普通索引
* 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。
* 需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。
* 将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作
* 由于唯一索引，所有更新操作都要先判断这个操作是否**违反唯一性约束**，因此都得把数据页读入到内存才能判断，因此，不需要使用change buffer；
* 优点：如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。
* 场景：
    * 对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统；
    * 假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价；
* 思考：change buffer 和 redo log类似点和区别？
    * redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗：具体可看09章详细讲解；


### .7. MYSQL调优
* 

### .8. 实战问题

#### .8.1. 如何避免长事务？
* 首先，从应用开发端来看：
    * 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。
    * 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。
    * 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）
* 其次，从数据库端来看：
    * 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；
    * Percona 的 pt-kill 这个工具不错，推荐使用；
    * 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；
    * 如果使用的是 MySQL  5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便

#### .8.2. 内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住
* 这个业务有大量插入数据的操作,他在前一天把其中的某个普通索引改成了唯一索引
* 第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：
    * 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；
    * 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。
    * 这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。但，这不是我们关注的重点。
* 第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：
    * 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；
    * 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。
    * 将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的

### .9. 其他知识点
* 顺序IO和随机IO花费的时间是不一样的（寻址时间），比如复制1G的压缩包和复制1G的html文件

#### .9.1. 局部性原理
* 局部性原理：局部性原理是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。
* 我们先将计算机分为数个层次：
    * 寄存器 64位
    * 一级缓存L1 4×64KB
    * 二级缓存L2 4×256KB
    * 三级缓存L3 8MB
    * 内存 4GB
    * 磁盘 1TB
* 可以看到这些层次一个比一个更大，CPU要工作了，它需要数据或者地址，从哪里来？先从一级缓存里面找，找不到就从二级缓存里面找，依次类推。假如CPU到磁盘才有，那么这个数据就会存入内存，再存入三级缓存、二级缓存、一级缓存，最后存入寄存器，CPU用它来计算了。
* 局部性原理： CPU的工作要高速，我们希望CPU需要的数据更多的就在L1里面，一找就找着。不希望更多的跑到下面内存乃至磁盘里面去找，这样会花更多的时间。所以当CPU用了一个数据，计算机会遇见性的存入其他等会儿CPU可能会用到的数据到L123内存，用到的可能性越大，就能存到越接近寄存器的层次。
* 时间局部性：程序有在一段时间内多次访问同一个数据块的倾向，这个写程序的都知道；
    * 如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。这当然是正确的，用过的数据当然可能再次被用到；
* 空间局部性：程序往往有访问一个聚集空间的数据块的倾向，参见数组的访问；
    * 在最近的将来将用到的信息很可能与现在正在使用的信息在空间地址上是临近的。正在使用的这个数据地址旁边的数据，当然也是很可能被用到的。比如数组什么的



* InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。
* MyISAM、InnoDB 使用B+树，InnoDB支持hash索引（自适应hash），MEMORY引擎使用hash索引
* 二叉树 -> BST -> AVL -> RED/Black（近似平衡树，插入和查找折中）
* B树有个概念叫做Degree，度，可以插入一个数据页的数据；
* B+树，为了扩大存储的条数，非叶子节点只存key（主键->唯一键->6字节的rowid，按照这个顺序找第一个存在的当作key）和指针，叶子节点存数据；叶子节点相互用双向链表连接，支持顺序读取。B+树本身支持随机读取，那么顺序和随机都支持了；
* 为什么选B+，为什么不用红黑树
    * IO性能，二叉树高度影响了IO次数； 
    * 按页存储，不是按值，契合B+树的度
* 为什么选B+，为什么不选B
    *
* mysqlB+树有几层？可能3（千万级别）、可能4，自动调整按照存储的数据量；
* 最左匹配原则（针对组合索引）：
    * 有一个name age 的组合索引
    * 必须要先匹配name 才能匹配到age
    * **where age = ? and name = ? 也是会匹配，优化器会调整顺序**
    * **where age = ? 不会匹配**
    * or 可能不走索引
* extra:using index -> 使用了覆盖索引
* 当一个表全部列一起做一个组合索引，那么怎么用or都会走索引

* 索引下推（组合索引）：把server层的筛选放到了引擎做
    * 有一个name age 的组合索引
    * （mysql5.6以前）先根据name去存储引擎中拿到所有的数据，然后在server层对age进行数据过滤
    * （mysql5.6以后）根据name，age两个列的值去获取数据，直接把数据返回；
* 优化器
    * CBO：基于成本的优化，mysql采用；
    * RBO：基于规则的优化
* select * from t1 join t2 on ???
    * 根据数据量，优化器会选择先加载t1还是t2，小表在前大表在后
    * 强制顺序加select straight_join
* 当创建一张表的时候，要不要创建主键？
    * 如果不用分布式，就使用主键，建议主键自增（不自增插入就会导致页分裂，维护困难）；
* 雪花算法/雪花模型（分布式id）/分布式
* 前缀索引