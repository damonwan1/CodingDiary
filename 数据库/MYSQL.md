# MYSQL笔记
-----
### 基础架构
* 一条sql在mysql中执行的流转过程：
![mysql流转过程图](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)
Mysql是插件式的，存储引擎层负责数据的存储和提取，支持InnoDB、MyISAM、Memory等，从图中可以看出，不同的存储引擎共用一个 Server 层，也就是从连接器到执行器的部分；
#### 连接器
* 负责跟客户端建立连接、获取权限、维持和管理连接
``` SQL
mysql -h$ip -P$port -u$user -p
输入密码
```
* 注意：一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，**只有再新建的连接**才会使用新的权限设置；
* show processlist 命令可以查看连接状态，有sleep（空闲状态）、query等；默认空闲8个小时就会断开，由wait_timeout参数设置；
* 由于建立连接过程复杂，建议使用**长连接**，但是长连接也有坑：
    * MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的**内存是管理在连接对象**里面的。这些资源会在**连接断开的时候才释放**。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了；
    * 解决方案1：定期断开长连接 或 占大内存的查询后，断开连接；
    * 解决方案2：MYSQL5.7后，通过mysql_reset_connection来重新初始化连接资源。

#### 查询缓存
* 之前执行过的语句及其结果可能会以key-value的形式存在查询缓存中；
* 查询缓存不推荐使用（mysql8.0后已被删除查询缓存）：
    * 失效频繁：只要有对一个表任何一行的更新，这个表所有查询缓存都被清空。因此只使用于静态表的业务，如系统配置表；
```
显示指定使用查询缓存
mysql> select SQL_CACHE * from T where ID=10；
```

#### 分析器
* 词法分析：MySQL 需要识别出里面的字符串分别是什么，代表什么；
    * MySQL 从你输入的"select"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”；
* 语法分析： 判断你输入的这个 SQL 语句是否满足 MySQL 语法；
* 解析器处理语法和解析查询, 生成一课对应的**解析树**。预处理器进一步检查解析树的合法。比如: 数据表和数据列是否存在, 别名是否有歧义等。如果通过则生成新的解析树，再提交给优化器。

#### 优化器
* 优化器是在表里面有多个索引的时候，**决定使用哪个索引**；或者在一个语句有多表关联（join）的时候，决定各个**表的连接顺序**

#### 执行器
* 开始执行语句。
    * 开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误；
    * 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个**引擎提供的接口**
* 数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行，在有些场景下，执行器调用一次，在引擎内部则扫描了多行，**因此引擎扫描行数跟 rows_examined 并不是完全相同的**；

### 日志系统
#### 重做日志 redo log （InnoDB引擎的日志）
* 类比记忆：孔乙己的酒馆，先黑板记账，后台还有一个账本，这叫WAL(Weite-Ahead Logging)；redo log就相当于黑板
* 原因：如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高；使用Redolog是顺序写，并且可以组提交，还有别的一些优化，收益最大是是这两个因素；
* 记录类型：Redo log不是记录数据页“更新之后的状态”，而是记录这个页**做了什么改动**
![redo log](https://static001.geekbang.org/resource/image/16/a7/16a7950217b3f0f4ed02db5db59562a7.png)
* write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。
* write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。
* 思想：有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 **crash-safe**

#### 归档日志 binlog （Server层的日志）
* 记录类型：Binlog有两种模式，statement格式的话是记sql语句， row格式（推荐）会记录行的内容，记两条，更新前和更新后都有。
* binlog和redolog 区别？
    * redo log 是**物理日志**，记录的是“在某个数据页上做了什么修改”；binlog 是**逻辑日志**，记录的是**这个语句的原始逻辑**，比如“给 ID=2 这一行的 c 字段加 1 ”
    * redo log 是**循环写的**，空间固定会用完；binlog 是可以**追加写入**的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
* 为了保证binlog 和 redo log的一致性，redo log 有prepare/commit状态，也称**两阶段提交**：
![两阶段提交](https://static001.geekbang.org/resource/image/2e/be/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png)
上图浅色是咋InnoDB中执行的，深色是在执行器中执行的；
* 这时候redolog只是完成了prepare, 而binlog又失败，那么事务本身会回滚。
---
* 怎么让数据库回复到半个月内任意一秒的状态？
    * 数据库需要定期做整库备份
    * 找到最近的一次全量备份，从备份的时间点起，将之后的binlog一次取出来，重放到你想要的时刻；
* 参数设置（保证事务成功，日志落盘）：
    * sync_binlog = 1，表示每次事务的 binlog 都持久化到磁盘（建议设置）
    * innodb_flush_log_at_trx_commit = 1，表示每次事务的 redo log 都直接持久化到磁盘（建议设置）

### 事务
* 事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的；
* InnoDB支持事务，MyISAM不支持事务；
* 事务的ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）
#### 隔离性
* 多个事务同时执行会出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，解决这些问题就出现**隔离级别**的概念。
* 事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable)
    * 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
    * 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
    * 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
    * 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行
* 实现方式：数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准
    * 在“读提交”隔离级别下，这个视图是在每个 SQL **语句开始执行**的时候创建的。
    * “**读未提交**”隔离级别下**直接返回记录上的最新值**，没有视图概念；
    * 在“可重复读”隔离级别下，这个视图是在**事务启动时创建的**，整个事务存在期间都用这个视图。
    * “**串行化**”隔离级别下直接用**加锁**的方式来避免并行访问。
* InnoDB默认隔离级别是RR，可重复度；参数transaction-isolation设置隔离级别；
---
* 可重复读 的实现方式 - 多版本并发控制（MVCC）
* 在 MySQL 中，实际上每条记录在**更新的时候**都会同时**记录一条回滚操作**。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。
* 假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录：
![回滚日志](https://static001.geekbang.org/resource/image/d9/ee/d9c313809e5ac148fc39feff532f0fee.png)
* 回滚日志总不能一直保留吧，什么时候删除呢？当系统里没有比这个回滚日志更早的 read-view 的时候。

### 锁
* 按照加锁的范围，MYSQL里面的锁分为：**全局锁、表级锁和行锁**；
* 业务的更新，增删改数据（DML)，加字段等修改表结构的操作（DDL）；
#### 全局锁
* 全局锁就是对整个**数据库实例**加锁：全局读锁（Flush tables with read lock - FTWRL）；
* 描述：当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。
* 场景：全库逻辑备份（在备份过程中整个库完全处于只读状态）
    * 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
    * 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。
* 替代： 因为实际上就是要保证备份时候，视图是逻辑一致不变的；
    * 使用官方逻辑备份工具mysqldump，并且使用参数-single-transaction，保证启动一个事务，这样RR隔离性下，拿到一致性视图，可以代替全局锁；
    * 全库只读，设置set global readonly = true；
* 选择： **像使用MyISAM引擎的，只能使用FTWRL，因为不支持事务；其他情况选择single-transaction，不建议使用全库设置readonly**（在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库、如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。）；

#### 表级锁
* 表级锁有两种表级别的锁：**表锁 、 元数据锁（meta data lock， MDL）**
* 表锁：** lock tables...read/write  -> unlock tables（或者客户端断开连接自动释放）
* 示例： 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表；
* 场景：对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发；
---
* 元数据锁（MDL）：**MDL 不需要显式使用，在访问一个表的时候会被自动加上**。MDL 的作用是，保证读写的正确性；
* 事务中的 MDL 锁，在**语句执行开始时申请**，但是语句结束后并不会马上释放，而会等到**整个事务提交后再释放**；
* 场景：（mysql5.5后系统自动加）当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。
    * **读锁之间不互斥**，因此你可以有多个线程同时对一张表增删改查。
    * **读写锁之间、写锁之间是互斥的**，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。
---
* 线上坑：虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。**给一个小表加个字段，导致整个库挂了**
    * A、B、C、D四个session，A、B对表t进行增删改查，分别获得读锁没问题；C对表t进行字段修改是写锁，而A、B还未释放读锁（A、B长事务，占用时间长），因此C被阻塞。问题是，之后的D、E、F、G也只是增删改查的读锁，但是由于C被阻塞，mysql内部有个等待队列，他们也被阻塞，对外表现为这个表完全不可读写了；
    * 这时候，如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满；
* 解决线上坑：**如何安全给小表加字段？**
    * 解决长事务：当有DDL变更的表，先暂停DDL或者kill长事务；
    * alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃，之后再循环这个过程（热点表请求频繁的情况下），语法如下：
    ``` SQL
   ALTER TABLE tbl_name NOWAIT add column ...
   ALTER TABLE tbl_name WAIT N add column ... 
    ```
* mysql 5.6支持online ddl，也就是对表操作增加字段等功能；
* Online DDL的过程是这样的：
1. 拿MDL写锁
2. 降级成MDL读锁
3. 真正做DDL
4. 升级成MDL写锁
5. 释放MDL锁

1、2、4、5如果没有锁冲突，执行时间非常短。第3步占用了DDL绝大部分时间，这期间这个表可以正常读写数据，是因此称为“online ”，但是刚刚的例子，是在第一步就堵住了；

#### 行锁
* 概念：行锁就是针对数据表中行记录的锁，但不一定是锁行（也可以锁索引），看各个引擎实现；
* MYSQL的行锁是在引擎层由各个引擎自己实现的，但并不是所有的引擎都支持行锁。
* 实现：InnoDB行锁是通过给索引上的索引项加锁来实现的。如果update的列没建索引，即使只update一条记录也会锁定整张表吗？是的，无索引情况，在两个不同事务中，更新同一列加不加limit 1，效果都是锁互斥；原因是没有索引的话，会导致全表扫描(表锁)，同时还会涉及回表(行锁)；
* 牢记：InnoDB这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！**
* 注意：**由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的**
---
* **两阶段锁协议**：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放（commit才释放，而不是语句结束）；
* 场景：如果事务中需要锁多个行，那么尽量把**最可能造成锁冲突的锁往后放**；
---
* 线上坑：电影票影院特价预售购买活动，Mysql挂了，上线查看，CPU消耗近100%，但整个数据库每秒就执行不到100个事务，why？
    * 很可能打开了**死锁检测**，导致O(n)级别的遍历，每个加入的线程都需要判断自己加入是否会导致死锁，如果并发量很大，这个CPU就会消耗很大，但是每秒却执行不了几个事务；
    * 解决方案1：业务代码确保不出现死锁，然后临时关掉死锁检测；
    * 解决方案2：使用中间件设置队列控制并发度，同时只允许10个线程更新，那么死锁检测的成本就会降低。
    * 解决方案3： 改变设计策略，因为实际上是 **增加影院账户余额的这行表被锁导致冲突**，那么把这行拆分成10行，以后统计影院账户余额把10行余额加起来不就可以了？现在冲突概率降低成了之前的1/10；
    ---
上面的延申，什么是**死锁**？
* **死锁**：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁；
    * 解决方案1：设置等待时间，直到超时。innodb_lock_wait_timeout;默认是50s，这个等待时间在线上系统是不能接受的，出现死锁等50s太夸张了吧，但是设太小了，可能没有死锁，只是在阻塞等待另一个事务执行而已。
    * 解决方案2：**主动死锁检测**，innodb_deadlock_detect默认就是打开的on，但是这个是由额外的开销的。检测自己锁住的和别的线程锁住的，是否存在相互依赖等待。
* 关于死锁检测
1. 一致性读不会加锁，就不需要做死锁检测；
（一致性读，又称为快照读。使用的是MVCC机制读取undo中的已经提交的数据。所以它的读取是非阻塞的。）
2. 并不是每次死锁检测都都要扫所有事务（算法中环的检测）。比如某个时刻，事务等待状态是这样的：

   B在等A，
   D在等C，
   现在来了一个E，发现E需要等D，那么E就判断跟D、C是否会形成死锁，这个死锁检测不用管B和A；
---
锁附录：
* [各种锁的介绍](https://www.csdn.net/gather_20/MtTaMgzsNDkxNy1ibG9n.html)

### 索引
* 主键索引：primary key，不允许空置；
* 唯一索引：非主键且键是唯一的，允许空置，主键索引不允许空置；
* 普通索引（二级索引、辅助索引）：列不是主键列也不是唯一列，在此上的索引；
* 全文索引：
* 组合索引：一个索引包含多个列，多个列共同组成索引

### 实战问题

### 其他知识点
* 顺序IO和随机IO花费的时间是不一样的（寻址时间），比如复制1G的压缩包和复制1G的html文件
* 局部性原理：局部性原理是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。
* 回表：
* MyISAM、InnoDB 使用B+树，InnoDB支持hash索引（自适应hash），MEMORY引擎使用hash索引
* 二叉树 -> BST -> AVL -> RED/Black（近似平衡树，插入和查找折中）
* B树有个概念叫做Degree，度，可以插入一个数据页的数据；
* B+树，为了扩大存储的条数，非叶子节点只存key（主键->唯一键->6字节的rowid，按照这个顺序找第一个存在的当作key）和指针，叶子节点存数据；叶子节点相互用双向链表连接，支持顺序读取。B+树本身支持随机读取，那么顺序和随机都支持了；
* 为什么选B+，为什么不用红黑树
    * IO性能，二叉树高度影响了IO次数； 
    * 按页存储，不是按值，契合B+树的度
* 为什么选B+，为什么不选B
    *
* mysqlB+树有几层？可能3（千万级别）、可能4，自动调整按照存储的数据量；
* 最左匹配原则（针对组合索引）：
    * 有一个name age 的组合索引
    * 必须要先匹配name 才能匹配到age
    * **where age = ? and name = ? 也是会匹配，优化器会调整顺序**
    * **where age = ? 不会匹配**
    * or 可能不走索引
* extra:using index -> 使用了覆盖索引
* 当一个表全部列一起做一个组合索引，那么怎么用or都会走索引

* 索引下推（组合索引）：把server层的筛选放到了引擎做
    * 有一个name age 的组合索引
    * （mysql5.6以前）先根据name去存储引擎中拿到所有的数据，然后在server层对age进行数据过滤
    * （mysql5.6以后）根据name，age两个列的值去获取数据，直接把数据返回；
* 优化器
    * CBO：基于成本的优化，mysql采用；
    * RBO：基于规则的优化
* select * from t1 join t2 on ???
    * 根据数据量，优化器会选择先加载t1还是t2，小表在前大表在后
    * 强制顺序加select straight_join
* 当创建一张表的时候，要不要创建主键？
    * 如果不用分布式，就使用主键，建议主键自增（不自增插入就会导致页分裂，维护困难）；