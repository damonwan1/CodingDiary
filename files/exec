#! /bin/bash

#1
spark-submit --deploy-mode cluster \
             --num-executors 50 \
             --executor-memory 4g \
             --executor-cores 2 \
             --conf spark.default.parallelism=500 \
             --queue root.service \
             --driver-memory 16g \
             --py-files model_DALEC_LAI_All.py,simulation_DALEC_LAI_All.py \
             parallelize_DALEC_LAI_All.py

             #--conf spark.default.parallelism=300 \

# 20*3	10:40:15 - 13:29:36	2:49:21 = 169:21
# 40*3	14:17:22 - 15:59:07	1:42:45 = 102:45
# 60*3	20:38:49 - 22:08:16	1:29:27 = 89:27
# 80*3	22:12:54 - 23:43:12	1:30:18 = 90:18
# 100*3	22:20:27 - 23:49:36	1:29:9 = 89:9
# 120*3	12:38:21 - 14:09:05	1:30:44 = 90:44
# ======================================================
# 140*3	14:12:40 - 15:42:49	1:30:9 = 90:9
# 140*1	20:05:14 - 21:34:23	1:29:9 = 89:9
# 140*2	22:16:51 - 23:45:07	1:29:16 = 89:16
# ======================================================
# 160*3	18:14:28 - 19:48:43	1:34:15 = 94:15

# 2
#spark-submit --master local[50] --py-files regulation_DALEC_LAI_All.py parallelize_Reg_DALEC_LAI_All.py

